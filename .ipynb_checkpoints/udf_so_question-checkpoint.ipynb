{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "spark_path = \"/Users/weizhong/stk/spark-1.6.0-bin-hadoop2.6\"\n",
    "\n",
    "os.environ['SPARK_HOME'] = spark_path\n",
    "os.environ['HADOOP_HOME'] = spark_path\n",
    "#os.environ['PYSPARK_PYTHON'] = 'C:\\Users\\Wei Zhong\\Anaconda3\\envs\\python2\\python' # <---\n",
    "\n",
    "sys.path.append(spark_path + \"/bin\")\n",
    "sys.path.append(spark_path + \"/python\")\n",
    "sys.path.append(spark_path + \"/python/pyspark/\")\n",
    "sys.path.append(spark_path + \"/python/lib\")\n",
    "sys.path.append(spark_path + \"/python/lib/pyspark.zip\")\n",
    "sys.path.append(spark_path + \"/python/lib/py4j-0.9-src.zip\")\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "sc = SparkContext(\"local\")\n",
    "sqlCtx = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate Random Data\n",
    "import itertools\n",
    "import random\n",
    "student_ids = ['student1', 'student2', 'student3']\n",
    "subjects = ['Math', 'Biology', 'Chemistry', 'Physics']\n",
    "random.seed(1)\n",
    "data = []\n",
    " \n",
    "for (student_id, subject) in itertools.product(student_ids, subjects):\n",
    "    data.append((student_id, subject, random.randint(0, 100)))\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "schema = StructType([\n",
    "            StructField(\"student_id\", StringType(), nullable=False),\n",
    "            StructField(\"subject\", StringType(), nullable=False),\n",
    "            StructField(\"score\", IntegerType(), nullable=False)\n",
    "    ])\n",
    " \n",
    "# Create DataFrame \n",
    "#from pyspark.sql import HiveContext\n",
    "#sqlContext = HiveContext(sc)\n",
    "rdd = sc.parallelize(data)\n",
    "df = sqlCtx.createDataFrame(rdd, schema)\n",
    "\n",
    "# create another dataframe\n",
    "first_name = [\"Granger\", \"Weasley\", \"Potter\"]\n",
    "data2 = []\n",
    "for i in range(len(student_ids)):\n",
    "    data2.append((student_ids[i], first_name[i]))\n",
    "\n",
    "schema = StructType([\n",
    "            StructField(\"student_id\", StringType(), nullable=False),\n",
    "            StructField(\"first_name\", StringType(), nullable=False)\n",
    "    ])\n",
    "\n",
    "rdd = sc.parallelize(data2)\n",
    "df2 = sqlCtx.createDataFrame(rdd, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|student_id|first_name|\n",
      "+----------+----------+\n",
      "|  student1|   Granger|\n",
      "|  student2|   Weasley|\n",
      "|  student3|    Potter|\n",
      "+----------+----------+\n",
      "\n",
      "+----------+---------+-----+\n",
      "|student_id|  subject|score|\n",
      "+----------+---------+-----+\n",
      "|  student1|     Math|   13|\n",
      "|  student1|  Biology|   85|\n",
      "|  student1|Chemistry|   77|\n",
      "|  student1|  Physics|   25|\n",
      "|  student2|     Math|   50|\n",
      "|  student2|  Biology|   45|\n",
      "|  student2|Chemistry|   65|\n",
      "|  student2|  Physics|   79|\n",
      "|  student3|     Math|    9|\n",
      "|  student3|  Biology|    2|\n",
      "|  student3|Chemistry|   84|\n",
      "|  student3|  Physics|   43|\n",
      "+----------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "student1\n"
     ]
    }
   ],
   "source": [
    "print len(student_id)\n",
    "\n",
    "print student_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
