{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.context.SparkContext object at 0x1068cd750>\n",
      "<pyspark.sql.context.SQLContext object at 0x10bc95a50>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "spark_path = \"/Users/weizhong/stk/spark-1.6.0-bin-hadoop2.6\"\n",
    "\n",
    "os.environ['SPARK_HOME'] = spark_path\n",
    "os.environ['HADOOP_HOME'] = spark_path\n",
    "\n",
    "sys.path.append(spark_path + \"/bin\")\n",
    "sys.path.append(spark_path + \"/python\")\n",
    "sys.path.append(spark_path + \"/python/pyspark/\")\n",
    "sys.path.append(spark_path + \"/python/lib\")\n",
    "sys.path.append(spark_path + \"/python/lib/pyspark.zip\")\n",
    "sys.path.append(spark_path + \"/python/lib/py4j-0.9-src.zip\")\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "sc = SparkContext(\"local\")\n",
    "sqlCtx = SQLContext(sc)\n",
    "\n",
    "print sc\n",
    "print sqlCtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B', ['A', 1]),\n",
       " ('B', ['C', 2]),\n",
       " ('A', ['C', 3]),\n",
       " ('A', ['B', 4]),\n",
       " ('A', ['D', 5])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sc.parallelize([('B',['A',1]),('B',['C',2]),('A',['C',3]),('A',['B',4]),('A',['D',5])])\n",
    "#xprime = x.map(lambda r: [(r[0], (r[1], r[2]))])\n",
    "x.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('B', ['A', 1]), ('B', ['C', 2]), ('A', ['C', 3]), ('A', ['B', 4]), ('A', ['D', 5])]\n",
      "[('A', [['C', 3], ['B', 4], ['D', 5]]), ('B', [['A', 1], ['C', 2]])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "zeroVal = []\n",
    "mergeVal = (lambda aggregated, el: aggregated + [(el)])\n",
    "mergeComb = (lambda agg1,agg2: agg1 + agg2 )  # append agg1 with agg2\n",
    "y = x.aggregateByKey(zeroVal,mergeVal,mergeComb)\n",
    "print(x.collect())\n",
    "print(y.collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B', ['A', 21]),\n",
       " ('B', ['C', 12]),\n",
       " ('A', ['C', 3]),\n",
       " ('A', ['B', 2]),\n",
       " ('A', ['D', 5])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sc.parallelize([('B','A',21),('B','C',12),('A','C',3),('A','B',2),('A','D',5)])\n",
    "xprime = x.map(lambda r: (r[0], [r[1], r[2]]))\n",
    "xprime.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('B', ['A', 21]), ('B', ['C', 12]), ('A', ['C', 3]), ('A', ['B', 2]), ('A', ['D', 5])]\n",
      "[('A', [['C', 3], ['B', 2], ['D', 5]]), ('B', [['A', 21], ['C', 12]])]\n",
      "[('A', [['B', 2]]), ('B', [['C', 12]])]\n"
     ]
    }
   ],
   "source": [
    "zeroVal = []\n",
    "mergeVal = (lambda aggregated, el: aggregated + [(el)])\n",
    "mergeComb = (lambda agg1,agg2: agg1 + agg2 )  # append agg1 with agg2\n",
    "y = xprime.aggregateByKey(zeroVal,mergeVal,mergeComb)\n",
    "print(xprime.collect())\n",
    "print(y.collect())\n",
    "\n",
    "# assuming it's sorted\n",
    "# take top k\n",
    "calls_k = 2\n",
    "takeTopK = (lambda r: (r[0], [i for i in r[1][1:calls_k]]))\n",
    "y = y.map(takeTopK)\n",
    "print(y.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A', ['B']], ['B', ['C']]]\n",
      "+------+----------+\n",
      "|a_imsi|callingcir|\n",
      "+------+----------+\n",
      "|     A|       [B]|\n",
      "|     B|       [C]|\n",
      "+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove counts\n",
    "y = y.map(lambda r: [r[0], [i[0] for i in r[1]]])\n",
    "print(y.collect())\n",
    "\n",
    "# convert to dataframe\n",
    "y_df = y.toDF([\"a_imsi\",\"callingcir\"])\n",
    "y_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-b46dac3618d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msortBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "y = y.sortBy(lambda r: x[1] for x in r)\n",
    "y.collect()\n",
    "y.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getCount(r): return (x[1] for x in r[1])\n",
    "\n",
    "foo = y.map(getCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.count()\n",
    "type(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
